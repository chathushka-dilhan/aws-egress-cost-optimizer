{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a conceptual Jupyter Notebook for Exploratory Data Analysis (EDA)\n",
    "# of your processed egress cost data.\n",
    "# You would run this on your SageMaker Notebook Instance.\n",
    "\n",
    "# --- Section 1: Setup and Data Loading ---\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Initialize SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket() # Or your specific processed data bucket\n",
    "\n",
    "# Define S3 path to processed data (output from Glue jobs)\n",
    "# This should match the target_path in your Glue job configuration.\n",
    "processed_data_s3_path = f\"s3://{bucket}/processed_egress_costs/aggregated_egress_costs/\" # Example path for CUR data\n",
    "flow_log_data_s3_path = f\"s3://{bucket}/processed_egress_costs/aggregated_flow_data/\" # Example path for Flow Log data\n",
    "\n",
    "print(f\"Loading processed egress costs from: {processed_data_s3_path}\")\n",
    "print(f\"Loading processed flow log data from: {flow_log_data_s3_path}\")\n",
    "\n",
    "# Load processed data (e.g., daily aggregated egress costs from CUR)\n",
    "# Ensure your Glue job outputs daily aggregated egress data in Parquet format.\n",
    "try:\n",
    "    df_egress_costs = sagemaker_session.read_parquet(processed_data_s3_path)\n",
    "    print(f\"Loaded egress costs data with shape: {df_egress_costs.shape}\")\n",
    "    print(df_egress_costs.head())\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not load egress costs data. Make sure Glue job has run and path is correct: {e}\")\n",
    "    df_egress_costs = pd.DataFrame()\n",
    "\n",
    "# Load processed flow log data (e.g., hourly aggregated flow data)\n",
    "try:\n",
    "    df_flow_logs = sagemaker_session.read_parquet(flow_log_data_s3_path)\n",
    "    print(f\"Loaded flow logs data with shape: {df_flow_logs.shape}\")\n",
    "    print(df_flow_logs.head())\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not load flow logs data. Make sure Glue job has run and path is correct: {e}\")\n",
    "    df_flow_logs = pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- Section 2: Exploratory Data Analysis (EDA) ---\n",
    "\n",
    "if not df_egress_costs.empty:\n",
    "    print(\"\\n--- EDA for Aggregated Egress Costs ---\")\n",
    "    df_egress_costs['usage_date'] = pd.to_datetime(df_egress_costs['usage_date'])\n",
    "    df_egress_costs = df_egress_costs.sort_values('usage_date')\n",
    "\n",
    "    # Visualize daily egress cost trends\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    plt.plot(df_egress_costs['usage_date'], df_egress_costs['daily_egress_cost_usd'], label='Daily Egress Cost (USD)')\n",
    "    plt.title('Daily Egress Cost Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cost (USD)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize egress cost by service\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='service_code', y='daily_egress_cost_usd', data=df_egress_costs.groupby('service_code').sum().reset_index())\n",
    "    plt.title('Total Egress Cost by Service')\n",
    "    plt.xlabel('Service Code')\n",
    "    plt.ylabel('Total Cost (USD)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Box plot to identify outliers in cost\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(y=df_egress_costs['daily_egress_cost_usd'])\n",
    "    plt.title('Box Plot of Daily Egress Cost')\n",
    "    plt.ylabel('Cost (USD)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if not df_flow_logs.empty:\n",
    "    print(\"\\n--- EDA for Aggregated Flow Logs ---\")\n",
    "    df_flow_logs['flow_date'] = pd.to_datetime(df_flow_logs['flow_date'])\n",
    "    df_flow_logs = df_flow_logs.sort_values(['flow_date', 'flow_hour'])\n",
    "\n",
    "    # Visualize hourly egress bytes from flow logs\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    df_flow_logs['datetime'] = df_flow_logs['flow_date'] + pd.to_timedelta(df_flow_logs['flow_hour'], unit='h')\n",
    "    plt.plot(df_flow_logs['datetime'], df_flow_logs['total_egress_bytes'], label='Hourly Egress Bytes')\n",
    "    plt.title('Hourly Egress Bytes from VPC Flow Logs Over Time')\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.ylabel('Bytes')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Top 10 destination IPs by egress bytes\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    top_dest_ips = df_flow_logs.groupby('destination_ip')['total_egress_bytes'].sum().nlargest(10).reset_index()\n",
    "    sns.barplot(x='destination_ip', y='total_egress_bytes', data=top_dest_ips)\n",
    "    plt.title('Top 10 Destination IPs by Egress Bytes')\n",
    "    plt.xlabel('Destination IP')\n",
    "    plt.ylabel('Total Egress Bytes')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Section 3: Feature Engineering Preview (Conceptual) ---\n",
    "# This section would demonstrate how to apply the feature_engineering.py logic\n",
    "# to your combined data, showing the resulting features.\n",
    "# You would typically combine df_egress_costs and df_flow_logs here based on date/time.\n",
    "\n",
    "# Example of combining (conceptual)\n",
    "df_combined = pd.merge(df_egress_costs, df_flow_logs, left_on='usage_date', right_on='flow_date', how='left')\n",
    "print(\"\\nCombined DataFrame head (conceptual):\")\n",
    "print(df_combined.head())\n",
    "\n",
    "# This notebook helps to understand your data before training a model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
