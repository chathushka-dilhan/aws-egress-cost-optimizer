{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffda08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a conceptual Jupyter Notebook for orchestrating SageMaker Training Jobs\n",
    "# and deploying test endpoints for your anomaly detection model.\n",
    "# You would run this on your SageMaker Notebook Instance.\n",
    "\n",
    "# --- Section 1: Setup ---\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn # For scikit-learn training\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer, JSONSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer, JSONDeserializer\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket() # Or your specific processed data bucket\n",
    "\n",
    "# Define S3 paths (these should match your Terraform outputs and data processing outputs)\n",
    "processed_features_s3_path = f\"s3://{bucket}/processed_egress_costs/processed_features/\" # Output from feature_engineering.py\n",
    "model_artifacts_s3_path_prefix = f\"s3://{bucket}/ml-model-artifacts/anomaly_detection/\" # Where model.joblib will be saved\n",
    "\n",
    "# --- Section 2: Prepare Training Data ---\n",
    "# In a real scenario, your feature engineering processing job would output\n",
    "# the 'processed_features.parquet' file.\n",
    "# For this notebook, we'll simulate or assume this file exists.\n",
    "# Ensure your processed data is correctly formatted for the training script.\n",
    "\n",
    "# Example: If you have a local processed_features.parquet for testing\n",
    "# local_data_path = 'path/to/your/local/processed_features.parquet'\n",
    "# training_data_s3_uri = sagemaker_session.upload_data(\n",
    "#     path=local_data_path,\n",
    "#     bucket=bucket,\n",
    "#     key_prefix='training_data_for_model'\n",
    "# )\n",
    "# print(f\"Training data uploaded to: {training_data_s3_uri}\")\n",
    "\n",
    "# For actual pipeline, the training job input would be the S3 path from the processing job\n",
    "training_data_s3_uri = processed_features_s3_path # This is the input channel for the training job\n",
    "\n",
    "print(f\"Using training data from: {training_data_s3_uri}\")\n",
    "\n",
    "# --- Section 3: Configure and Run SageMaker Training Job ---\n",
    "# Define the SKLearn Estimator to run your 'training_script.py'\n",
    "# The 'source_dir' should point to the directory containing your training_script.py\n",
    "# and any other necessary files (e.g., requirements.txt if using custom libraries).\n",
    "# This directory will be uploaded to S3 by SageMaker.\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='training_script.py',\n",
    "    source_dir='../', # Points to 'ml_models/anomaly_detection/' where training_script.py resides\n",
    "    role=role,\n",
    "    instance_type='ml.m5.xlarge', # Matches your Terraform variable for training\n",
    "    instance_count=1,\n",
    "    framework_version='0.23-1', # scikit-learn version used in your script\n",
    "    py_version='py3',           # Python version\n",
    "    hyperparameters={\n",
    "        'n_estimators': 100,\n",
    "        'contamination': 0.01,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    output_path=model_artifacts_s3_path_prefix, # S3 path where model artifacts will be saved\n",
    "    base_job_name='egress-anomaly-detector-training'\n",
    ")\n",
    "\n",
    "# Start the training job\n",
    "print(\"Starting SageMaker training job...\")\n",
    "sklearn_estimator.fit({'train': training_data_s3_uri})\n",
    "print(\"Training job completed.\")\n",
    "\n",
    "# The trained model artifact (model.joblib) will be at:\n",
    "# s3://<your-bucket>/ml-model-artifacts/anomaly_detection/egress-anomaly-detector-training-<job-timestamp>/output/model.tar.gz\n",
    "# You would extract model.joblib from this tar.gz for direct S3 upload or endpoint creation.\n",
    "\n",
    "# --- Section 4: Deploy Test Endpoint (Optional, for quick validation) ---\n",
    "# This deploys a temporary endpoint for testing the 'inference_script.py'.\n",
    "# For production, you'd use the SageMaker Model and Endpoint resources defined in Terraform.\n",
    "test_endpoint_name = f\"{os.environ.get('PROJECT_NAME', 'test')}-anomaly-ep-test\" # Use a unique test name\n",
    "\n",
    "print(f\"Deploying test endpoint: {test_endpoint_name}...\")\n",
    "predictor = sklearn_estimator.deploy(\n",
    "    instance_type='ml.t2.medium', # Matches your Terraform variable for inference\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=test_endpoint_name,\n",
    "    serializer=JSONSerializer(), # Assuming your inference_script expects JSON\n",
    "    deserializer=JSONDeserializer() # Assuming your inference_script outputs JSON\n",
    ")\n",
    "print(f\"Test endpoint deployed: {predictor.endpoint_name}\")\n",
    "\n",
    "# --- Section 5: Testing Inference ---\n",
    "# Prepare sample data for inference. This should mimic the structure of data\n",
    "# that the inference_script.py expects after feature engineering.\n",
    "# Example: a single data point with numerical features.\n",
    "# In a real scenario, you'd feed actual recent data.\n",
    "sample_inference_data = pd.DataFrame({\n",
    "    'daily_egress_cost_usd': [1500.0],\n",
    "    'daily_egress_usage_amount': [1500000.0],\n",
    "    # Add other numerical features that your preprocessor outputs\n",
    "    # For categorical features, you'd provide the raw categorical values\n",
    "    # and expect the preprocessor (if saved and loaded in inference_script)\n",
    "    # to handle the one-hot encoding.\n",
    "    # For this simple example, ensure the input matches the numerical features\n",
    "    # expected by IsolationForest.\n",
    "})\n",
    "\n",
    "print(\"\\nSending sample data for inference:\")\n",
    "print(sample_inference_data)\n",
    "\n",
    "try:\n",
    "    predictions = predictor.predict(sample_inference_data.to_json(orient='records'))\n",
    "    print(\"\\nSample inference result:\")\n",
    "    print(predictions)\n",
    "    # Expected output will be a JSON string from inference_script.py\n",
    "    # Example: [{\"daily_egress_cost_usd\": 1500.0, ..., \"is_anomaly\": 1, \"anomaly_score\": -0.123}]\n",
    "except Exception as e:\n",
    "    print(f\"Error during inference: {e}\")\n",
    "\n",
    "# --- Section 6: Cleanup (IMPORTANT: Delete test endpoint to avoid charges) ---\n",
    "print(f\"\\nDeleting test endpoint: {predictor.endpoint_name}...\")\n",
    "predictor.delete_endpoint()\n",
    "print(\"Test endpoint deleted.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
